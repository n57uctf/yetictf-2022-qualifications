{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179864dd-56cc-4eb2-b9c9-0658bf9a20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e29bf9f-a97d-4cea-ae58-c3d23c1d5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, cast, Dict, List, Optional, Tuple\n",
    "class AnalDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        path, target = self.samples[index]\n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return path, (sample, target)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f70a201-db06-46c5-bd26-d8671b55a0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 10000\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_DATASET = 'dataset/jpg/MNIST - JPG - testing/'\n",
    "MEAN, STD = [0.1307], [0.3081]\n",
    "dataset = AnalDataset(root=PATH_TO_DATASET, \n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.Grayscale(num_output_channels=1), \n",
    "                          transforms.ToTensor(), \n",
    "                          transforms.Normalize(mean=MEAN, std=STD)]))\n",
    "print(f\"Length {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f7fbf2-5089-4f9f-a2f9-8b2bf2c855fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path='dataset/jpg/MNIST - JPG - testing/1/1189.jpg'; target=1; shape=torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "path, (tensor_image, target) = dataset[1001]\n",
    "plt.imshow(  tensor_image.permute(1, 2, 0), cmap=\"gray\")\n",
    "print(f\"{path=}; {target=}; shape={tensor_image.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08017551-deab-42f2-8d33-b9bf22ca421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74284a72-9d66-46a8-9828-91b105f0332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = 'anal-model-jit-script.pth'\n",
    "model = torch.jit.load(PATH_TO_MODEL)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee026c1-da54-46c7-b963-b72768028f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking images:   0%|                                                                     | 0/100 [00:00<?, ?batchs/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return forward_call(*input, **kwargs)\n",
      "Checking images: 100%|███████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.23batchs/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "wrongs = []\n",
    "rights = []\n",
    "images = {}\n",
    "with torch.no_grad():\n",
    "    for paths, (tensor_images, targets) in tqdm(dataloader, desc=\"Checking images\", unit=\"batchs\",leave=True):\n",
    "        tensor_images, targets = tensor_images.cuda(), targets.cuda()\n",
    "        logits = model(tensor_images)\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predictions = torch.max(probabilities, dim=1)[1]\n",
    "        mask = predictions.eq(targets)\n",
    "        \n",
    "        wrong_indexes = torch.where(mask == False)[0]\n",
    "        right_indexes = torch.where(mask == True)[0]\n",
    "        for wrong_index in wrong_indexes:\n",
    "            wrong_path = paths[wrong_index]\n",
    "            wrong_pred = predictions[wrong_index].item()\n",
    "            true = targets[wrong_index].item()\n",
    "            wrongs.append((wrong_path, wrong_pred, true))\n",
    "            images.update({wrong_path: tensor_images[wrong_index]})\n",
    "        \n",
    "        for right_index in right_indexes:\n",
    "            right_path = paths[right_index]\n",
    "            right_pred = predictions[right_index].item()\n",
    "            rights.append((right_path, right_pred))\n",
    "            images.update({right_path: tensor_images[right_index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de495e14-409c-415a-bfc9-343f0cd8da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--TRUE-+-FALSE-+\n",
      "|  9892 |  108  |\n",
      "|-------+-------|\n",
      "|   10000 all   |\n",
      "+---------------+\n",
      "\n",
      "wrong example: ('dataset/jpg/MNIST - JPG - testing/8/8408.jpg', 5, 8);\n",
      "right example: ('dataset/jpg/MNIST - JPG - testing/0/3818.jpg', 0);\n"
     ]
    }
   ],
   "source": [
    "import random as r\n",
    "print(f\"+--TRUE-+-FALSE-+\\n|  {len(rights)} |  {len(wrongs)}  |\\n|-------+-------|\\n|   {len(images)} all   |\\n+---------------+\\n\")\n",
    "wrong_example = r.choice(wrongs)\n",
    "right_example = r.choice(rights)\n",
    "print(f\"wrong example: {wrong_example};\\nright example: {right_example};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982204c3-a4a1-4912-858f-bbe4dc95be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_sample = r.sample(rights, 995)\n",
    "wrong_sample = r.sample(wrongs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3daa00e0-02d3-4c71-816b-d9fdea5f31e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Каталог не существует. Создаём...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "PATH_TO_OUTPUT  = \"MNIST_test_data/\"\n",
    "\n",
    "if os.path.exists(PATH_TO_OUTPUT):\n",
    "    print(\"Каталог существует. Очищаем...\")\n",
    "    files = glob.glob(PATH_TO_OUTPUT+'*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "else:\n",
    "    print(\"Каталог не существует. Создаём...\")\n",
    "    os.mkdir(PATH_TO_OUTPUT)\n",
    "    \n",
    "for target_num in range(10):\n",
    "    current_path = os.path.join(PATH_TO_OUTPUT, str(target_num))\n",
    "    os.mkdir(current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ed317f-f9b7-460c-8ba3-8754aeb7d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "flag =\"YetiCTF{i_hate_these_dataset_anomalies}\" \n",
    "separate = lambda string: textwrap.wrap(string, (len(string)//len(wrong_sample) + 1))\n",
    "partition = separate(flag)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cdc6444-b6ca-4077-b12b-71f87cac1f40",
   "metadata": {},
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install exif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c094bd07-5d5c-471e-9522-2870dcdbbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image\n",
    "for index, wrong in enumerate(wrong_sample):\n",
    "    path, prediction, target = wrong\n",
    "    with open(path, \"rb\") as unpredictable:\n",
    "        image = Image(unpredictable)\n",
    "        if image.has_exif: \n",
    "            image.delete_all() \n",
    "        image.set(\"image_description\", f\"({index + 1}/{len(partition)}):{partition[index]}\")\n",
    "    mark = path.rpartition(\"/\")[-1]\n",
    "    path_to_save = f\"{PATH_TO_OUTPUT}/{target}/{mark}\"\n",
    "    with open(path_to_save, 'wb') as saving_file:\n",
    "        saving_file.write(image.get_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c999948-6d4f-4a7b-9150-8624700afd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "for index, right in enumerate(right_sample):\n",
    "    path, target = right\n",
    "    with open(path, \"rb\") as predictable:\n",
    "        image = Image(predictable)\n",
    "        if image.has_exif: \n",
    "            image.delete_all() \n",
    "        random_value = ''.join([r.choice(string.ascii_letters + string.digits) for n in range(16)])\n",
    "        image.set(\"image_description\", f\"({(index % len(partition) + 1)}/{len(partition)}):{random_value}\")\n",
    "    mark = path.rpartition(\"/\")[-1]\n",
    "    path_to_save = f\"{PATH_TO_OUTPUT}/{target}/{mark}\"\n",
    "    with open(path_to_save, 'wb') as saving_file:\n",
    "        saving_file.write(image.get_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8051c0dd-7f06-42eb-aed7-19ba5f724a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\MyCodes\\\\Projects\\\\YetiCTF\\\\MNISTED - Not tested\\\\dev\\\\MNIST_test_data.zip'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive(PATH_TO_OUTPUT, 'zip', PATH_TO_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d597ca-79fd-40ad-b2a1-ddfbeec9fa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4c8b6-a3b5-4727-b9b2-79c73f5d27d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f2364-9c8c-4ec4-ac28-41f4f07f81e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8fc380-620c-49eb-bbbd-5f003afadca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
