{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456249d3-0a6f-4129-b4b3-0bfd99809d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b548e1-f024-4a7f-9682-ef9ca9acd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL = \"anal-model-jit-script.pth\"\n",
    "PATH_TO_DATASET = \"MNIST_test_data\"\n",
    "MEAN, STD = [0.1307], [0.3081]\n",
    "BATCH_SIZE = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95eb736e-5751-4b84-84af-a2cc199dc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, cast, Dict, List, Optional, Tuple\n",
    "class AnalDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        path, target = self.samples[index]\n",
    "        path = path.replace(\"\\\\\", \"/\")\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return path, (sample, target)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a722f51-f0f2-451b-b07b-c6c2ac05e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 1000\n"
     ]
    }
   ],
   "source": [
    "dataset = AnalDataset(root=PATH_TO_DATASET, \n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.Grayscale(num_output_channels=1), \n",
    "                          transforms.ToTensor(), \n",
    "                          transforms.Normalize(mean=MEAN, std=STD)]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(f\"Length {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55bfc7f3-9615-4d24-bb4f-d4cec12bdd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path='MNIST_test_data/0/101.jpg'; target=0; shape=torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "path, (tensor_image, target) = dataset[1]\n",
    "plt.imshow(  tensor_image.permute(1, 2, 0), cmap=\"gray\")\n",
    "print(f\"{path=}; {target=}; shape={tensor_image.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3b8c62-4c7e-4c36-86eb-6998c41e8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(PATH_TO_MODEL, map_location=DEVICE)\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c43fc5-6ff5-478c-8a0a-0e0f3dfcc72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking images:   0%|                                                                      | 0/10 [00:00<?, ?batchs/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1051: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return forward_call(*input, **kwargs)\n",
      "Checking images: 100%|█████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.23batchs/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "wrongs = []\n",
    "images = {}\n",
    "with torch.no_grad():\n",
    "    for paths, (tensor_images, targets) in tqdm(dataloader, desc=\"Checking images\", unit=\"batchs\",leave=True):\n",
    "        tensor_images, targets = tensor_images.cuda(), targets.cuda()\n",
    "        logits = model(tensor_images)\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        predictions = torch.max(probabilities, dim=1)[1]\n",
    "        mask = predictions.eq(targets)\n",
    "        wrong_indexes = torch.where(mask == False)[0]\n",
    "        # right_indexes = torch.where(mask == True)[0]\n",
    "        for wrong_index in wrong_indexes:\n",
    "            wrong_path = paths[wrong_index]\n",
    "            wrong_pred = predictions[wrong_index].item()\n",
    "            target = targets[wrong_index].item()\n",
    "            wrongs.append((wrong_path, wrong_pred, target))\n",
    "            images.update({wrong_path: tensor_images[wrong_index]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "702f0a65-3f2a-44c3-9184-a401787d6048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_test_data/2/1654.jpg: predict=7; target=2\n",
      "MNIST_test_data/2/9811.jpg: predict=0; target=2\n",
      "MNIST_test_data/7/3136.jpg: predict=4; target=7\n",
      "MNIST_test_data/7/846.jpg: predict=0; target=7\n",
      "MNIST_test_data/8/582.jpg: predict=2; target=8\n"
     ]
    }
   ],
   "source": [
    "for wrong in wrongs:\n",
    "    path, pred, target = wrong\n",
    "    print(f\"{path}: predict={pred}; target={target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919b7193-f0a6-456e-b67a-8ebe5d0e7ff9",
   "metadata": {},
   "source": [
    "----------------------\n",
    "Далее тупа идём по этим путям, залазим в метаданные и по частям собирает флаг....\n",
    "1. 582: (1/5):YetiCTF{\n",
    "2. 3136: (2/5):i_hate_t\n",
    "3. 9811: (3/5):hese_dat\n",
    "4. 1654: (4/5):aset_ano\n",
    "5. 846: (5/5):malies}\n",
    "---------------------\n",
    "#### FLAG: YetiCTF{i_hate_these_dataset_anomalies}\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224bffb-02e1-4652-81d3-08a9af7b5a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e88a3-59f5-48f6-a37f-6ce191e71753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
